{
 "cells": [
  {
   "cell_type": "code",
   "id": "d52d5f08-6cb5-446f-90b8-5856799bdfce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T19:30:59.246568Z",
     "start_time": "2024-09-30T19:30:59.243791Z"
    }
   },
   "source": [
    "import chess\n",
    "import chess.engine\n",
    "import pandas\n",
    "from utils import *\n",
    "from main import *\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import threading\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\n",
    "import json\n",
    "from typing import Dict, Any, List, Tuple\n",
    "from collections import defaultdict"
   ],
   "outputs": [],
   "execution_count": 73
  },
  {
   "cell_type": "code",
   "id": "8c6be6c4-abf1-48ec-b45d-bbbfafcf83e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T19:31:01.423455Z",
     "start_time": "2024-09-30T19:31:01.417615Z"
    }
   },
   "source": [
    "class Config:\n",
    "    def __init__(self):\n",
    "        self.data_root = 'pgn'\n",
    "        self.seed = 42\n",
    "        self.num_workers = 8\n",
    "        self.verbose = True\n",
    "        self.max_epochs = 1\n",
    "        self.max_ply = 300\n",
    "        self.clock_threshold = 30\n",
    "        self.chunk_size = 8000  # Note: This is a string in your argparse, but consider changing it to int if applicable\n",
    "        self.start_year = 2013\n",
    "        self.start_month = 1\n",
    "        self.end_year = 2019\n",
    "        self.end_month = 12\n",
    "        self.from_checkpoint = False\n",
    "        self.checkpoint_year = 2018\n",
    "        self.checkpoint_month = 12\n",
    "        self.test_year = 2024\n",
    "        self.test_month = 1\n",
    "        self.num_cpu_left = 4\n",
    "        self.model = 'ViT'  # Default model type\n",
    "        self.lr = 1e-4\n",
    "        self.wd = 1e-5\n",
    "        self.batch_size = 30000\n",
    "        self.first_n_moves = 10\n",
    "        self.last_n_moves = 10\n",
    "        self.dim_cnn = 256\n",
    "        self.dim_vit = 1024\n",
    "        self.num_blocks_cnn = 5\n",
    "        self.num_blocks_vit = 2\n",
    "        self.input_channels = 18\n",
    "        self.vit_length = 8\n",
    "        self.elo_dim = 128\n",
    "        self.side_info = True\n",
    "        self.max_games_per_elo_range = 20\n",
    "        self.value = True\n",
    "        self.value_coefficient = 1\n",
    "        self.side_info_coefficient = 1"
   ],
   "outputs": [],
   "execution_count": 74
  },
  {
   "cell_type": "code",
   "id": "d654881a-6cb4-477f-a329-e6bf5d5c45fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T19:31:03.471677Z",
     "start_time": "2024-09-30T19:31:03.196037Z"
    }
   },
   "source": [
    "cfg = Config()\n",
    "all_moves = get_all_possible_moves()\n",
    "all_moves_dict = {move: i for i, move in enumerate(all_moves)}\n",
    "elo_dict = create_elo_dict()\n",
    "move_dict = {v: k for k, v in all_moves_dict.items()}\n",
    "\n",
    "trained_model_path = \"weights.v2.pt\"\n",
    "ckpt = torch.load(trained_model_path, map_location=torch.device('cpu'))\n",
    "model = MAIA2Model(len(all_moves), elo_dict, cfg)\n",
    "model = torch.nn.DataParallel(model)\n",
    "model.load_state_dict(ckpt['model_state_dict'])\n",
    "model.eval()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<1100': 0, '1100-1199': 1, '1200-1299': 2, '1300-1399': 3, '1400-1499': 4, '1500-1599': 5, '1600-1699': 6, '1700-1799': 7, '1800-1899': 8, '1900-1999': 9, '>=2000': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hp/j90w_shj791fd2xw8mx5j7xm0000gn/T/ipykernel_36566/729794498.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(trained_model_path, map_location=torch.device('cpu'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): MAIA2Model(\n",
       "    (chess_cnn): ChessResNet(\n",
       "      (conv1): Conv2d(18, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (layers): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (dropout): Dropout(p=0.5, inplace=False)\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (dropout): Dropout(p=0.5, inplace=False)\n",
       "        )\n",
       "        (2): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (dropout): Dropout(p=0.5, inplace=False)\n",
       "        )\n",
       "        (3): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (dropout): Dropout(p=0.5, inplace=False)\n",
       "        )\n",
       "        (4): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (dropout): Dropout(p=0.5, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (conv_last): Conv2d(256, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn_last): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (to_patch_embedding): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=1024, bias=True)\n",
       "      (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (layers): ModuleList()\n",
       "      (elo_layers): ModuleList(\n",
       "        (0-1): 2 x ModuleList(\n",
       "          (0): EloAwareAttention(\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (attend): Softmax(dim=-1)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (to_qkv): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "            (elo_query): Linear(in_features=256, out_features=1024, bias=False)\n",
       "            (to_out): Sequential(\n",
       "              (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (1): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): FeedForward(\n",
       "            (net): Sequential(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (2): GELU(approximate='none')\n",
       "              (3): Dropout(p=0.1, inplace=False)\n",
       "              (4): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (5): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fc_1): Linear(in_features=1024, out_features=1880, bias=True)\n",
       "    (fc_2): Linear(in_features=1024, out_features=2021, bias=True)\n",
       "    (fc_3): Linear(in_features=128, out_features=1, bias=True)\n",
       "    (fc_3_1): Linear(in_features=1024, out_features=128, bias=True)\n",
       "    (elo_embedding): Embedding(11, 128)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (last_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 75
  },
  {
   "cell_type": "code",
   "id": "651ba2fb-5f4e-4e80-aa93-9de225d8f84d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T19:34:39.297664Z",
     "start_time": "2024-09-30T19:33:39.076609Z"
    }
   },
   "source": [
    "def extract_puzzle_data(json_line):\n",
    "    data = json.loads(json_line)\n",
    "    fen = data['fen']\n",
    "    best_move = data['evals'][0]['pvs'][0]['line'].split()[0]\n",
    "    best_cp = data['evals'][0]['pvs'][0].get('cp', 100000)\n",
    "    \n",
    "    best_moves = []\n",
    "    \n",
    "    pvs = []\n",
    "    for eval in data['evals']:\n",
    "        for pv in eval['pvs']:\n",
    "            pvs.append(pv)\n",
    "            \n",
    "    for pv in pvs:\n",
    "        if abs(pv.get('cp', 0) - best_cp) < 30:\n",
    "            best_moves.append(pv['line'].split()[0])\n",
    "    \n",
    "    \n",
    "    elo_dict = {\n",
    "        '<1100': 0, '1100-1199': 1, '1200-1299': 2, '1300-1399': 3, '1400-1499': 4,\n",
    "        '1500-1599': 5, '1600-1699': 6, '1700-1799': 7, '1800-1899': 8, '1900-1999': 9,\n",
    "        '>=2000': 10\n",
    "    }\n",
    "    \n",
    "    maia_data = {}\n",
    "    for elo_range, category in elo_dict.items():\n",
    "        if elo_range in data:\n",
    "            move_probs = data[elo_range]['move_probs']\n",
    "            top_maia_move = max(move_probs, key=move_probs.get)\n",
    "            best_move_prob = move_probs.get(best_move, 0)\n",
    "            \n",
    "            maia_data[category] = {\n",
    "                'top_maia_move': top_maia_move,\n",
    "                'best_move_prob': best_move_prob\n",
    "            }\n",
    "    \n",
    "    return {\n",
    "        'fen': fen,\n",
    "        'best_move': best_move,\n",
    "        'maia_data': maia_data,\n",
    "        'best_moves': list(set(best_moves))\n",
    "    }\n",
    "\n",
    "def is_monotonic(maia_data: Dict[int, Dict[str, Any]]) -> bool:\n",
    "    probs = [data['best_move_prob'] for data in maia_data.values()]\n",
    "    return all(probs[i] <= probs[i+1] for i in range(len(probs)-1))\n",
    "\n",
    "def is_transitional(maia_data: Dict[int, Dict[str, Any]], best_moves: List[str]) -> Tuple[bool, int]:\n",
    "    moves = [data['top_maia_move'] for data in maia_data.values()]\n",
    "    elo_categories = sorted(maia_data.keys())\n",
    "    \n",
    "    # Check if all moves are correct (not truly transitional)\n",
    "    if all(move in best_moves for move in moves):\n",
    "        return False, -1\n",
    "    \n",
    "    for x in range(1, len(elo_categories)):\n",
    "        if all(moves[i] not in best_moves for i in range(x)) and \\\n",
    "           all(moves[i] in best_moves for i in range(x, len(moves))):\n",
    "            return True, elo_categories[x]\n",
    "    return False, -1\n",
    "\n",
    "def analyze_puzzle(puzzle_data: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    fen = puzzle_data['fen']\n",
    "    best_move = puzzle_data['best_move']\n",
    "    maia_data = puzzle_data['maia_data']\n",
    "    best_moves = puzzle_data['best_moves']\n",
    "    \n",
    "    monotonic = is_monotonic(maia_data)\n",
    "    transitional, transition_point = is_transitional(maia_data, best_moves)\n",
    "    all_correct = all(data['top_maia_move'] == best_move for data in maia_data.values())\n",
    "    \n",
    "    return {\n",
    "        'fen': fen,\n",
    "        'best_move': best_move,\n",
    "        'maia_moves': {elo: data['top_maia_move'] for elo, data in maia_data.items()},\n",
    "        'maia_probs': {elo: data['best_move_prob'] for elo, data in maia_data.items()},\n",
    "        'is_monotonic': monotonic,\n",
    "        'is_transitional': transitional,\n",
    "        'transition_point': transition_point,\n",
    "        'is_both': monotonic and transitional,\n",
    "        'all_correct': all_correct,\n",
    "    }\n",
    "\n",
    "def process_puzzles(file_path, special_fens, best_transitional_moves, all_best_transitional_moves, transitional_maia_moves, counters, transition_points) -> tuple:\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            puzzle_data = extract_puzzle_data(line)\n",
    "            analyzed_data = analyze_puzzle(puzzle_data)\n",
    "            # results.append(analyzed_data)\n",
    "            \n",
    "            counters['total'] += 1\n",
    "            if analyzed_data['is_monotonic']:\n",
    "                counters['monotonic'] += 1\n",
    "                special_fens['monotonic'].append(analyzed_data['fen'])\n",
    "            if analyzed_data['is_transitional']:\n",
    "                counters['transitional'] += 1\n",
    "                special_fens['transitional'].append(analyzed_data['fen'])\n",
    "                transition_points.append(analyzed_data['transition_point'])\n",
    "                best_transitional_moves.append(puzzle_data['best_move'])\n",
    "                all_best_transitional_moves.append(puzzle_data['best_moves'])\n",
    "                transitional_maia_moves.append(analyzed_data['maia_moves'])\n",
    "            if analyzed_data['is_both']:\n",
    "                counters['both'] += 1\n",
    "                special_fens['both'].append(analyzed_data['fen'])\n",
    "            if analyzed_data['all_correct']:\n",
    "                counters['all_correct'] += 1\n",
    "    \n",
    "    # df = pd.DataFrame(results)\n",
    "    return special_fens, counters, transition_points, best_transitional_moves, transitional_maia_moves\n",
    "\n",
    "special_fens = defaultdict(list)\n",
    "counters = {'total': 0, 'monotonic': 0, 'transitional': 0, 'both': 0, 'all_correct': 0}\n",
    "transition_points = []\n",
    "best_transitional_moves = []\n",
    "all_best_transitional_moves = []\n",
    "transitional_maia_moves = []\n",
    "\n",
    "for i in tqdm(range(9)):\n",
    "    file_path = f'lichess_db_eval_chunk_{i}.jsonl'\n",
    "    special_fens, counters, transition_points, best_transitional_moves, transitional_maia_moves = process_puzzles(file_path, special_fens, best_transitional_moves, all_best_transitional_moves, transitional_maia_moves, counters, transition_points)\n",
    "print(transitional_maia_moves[0])\n",
    "total_non_all_correct = counters['total'] - counters['all_correct']\n",
    "print(\"Total positions:\", counters['total'])\n",
    "print(\"Positions where all Maia2 predictions are correct:\", counters['all_correct'], f\"({counters['all_correct']/counters['total']:.2%})\")\n",
    "print(\"Monotonic positions:\", counters['monotonic'], f\"({counters['monotonic']/counters['total']:.2%})\")\n",
    "print(\"Transitional positions:\", counters['transitional'], f\"({counters['transitional']/total_non_all_correct:.2%} of non-all-correct positions)\")\n",
    "print(\"Both monotonic and transitional:\", counters['both'], f\"({counters['both']/total_non_all_correct:.2%} of non-all-correct positions)\")\n",
    "\n",
    "with open('trans_mono_positions.json', 'w') as f:\n",
    "    json.dump(special_fens, f, indent=2)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [01:00<00:00,  6.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'c6g2', 1: 'f7g7', 2: 'f7g7', 3: 'f7g7', 4: 'f7g7', 5: 'f7g7', 6: 'f7g7', 7: 'f7g7', 8: 'f7g7', 9: 'f7g7', 10: 'f7g7'}\n",
      "Total positions: 900000\n",
      "Positions where all Maia2 predictions are correct: 283697 (31.52%)\n",
      "Monotonic positions: 222689 (24.74%)\n",
      "Transitional positions: 90562 (14.69% of non-all-correct positions)\n",
      "Both monotonic and transitional: 45695 (7.41% of non-all-correct positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 78
  },
  {
   "cell_type": "code",
   "id": "2c6a9028-977f-4545-a081-5841bdb9c312",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T19:35:20.041654Z",
     "start_time": "2024-09-30T19:35:20.036104Z"
    }
   },
   "source": [
    "def is_piece_no_longer_under_attack(fen: str, move: str, square_index) -> bool:\n",
    "    \"\"\"\n",
    "    Determines if a piece on the given square index was under attack before the move\n",
    "    and is no longer under attack after the move.\n",
    "\n",
    "    Parameters:\n",
    "    fen (str): The FEN string representing the current board position.\n",
    "    move (str): The move in UCI format (e.g., 'e2e4').\n",
    "    square_index (int): The square to check, as an index between 0 and 63 (0 = 'a1', 63 = 'h8').\n",
    "\n",
    "    Returns:\n",
    "    bool: True if the piece on the square was under attack before the move but is no longer under attack after.\n",
    "    \"\"\"\n",
    "    # Load the board from the given FEN\n",
    "    board = chess.Board(fen)\n",
    "\n",
    "    piece_before_move = board.piece_at(square_index)\n",
    "\n",
    "    # Function to count attacks and defenses on the square\n",
    "    def is_under_attack(board, square_index):\n",
    "        attackers = board.attackers(chess.BLACK, square_index)  # Opponent's attackers\n",
    "        defenders = board.attackers(chess.WHITE, square_index)  # Defenders (current player's pieces)\n",
    "\n",
    "        return len(attackers) > len(defenders)\n",
    "\n",
    "    # Check if the square is under attack before the move\n",
    "    was_under_attack_before = is_under_attack(board, square_index) and piece_before_move is not None and piece_before_move.color is not chess.BLACK\n",
    "\n",
    "    # Make the move\n",
    "    move_obj = chess.Move.from_uci(move)\n",
    "    if not board.is_legal(move_obj):\n",
    "        return False\n",
    "\n",
    "    board.push(move_obj)  # Apply the move\n",
    "\n",
    "    # Check if there is still a piece on the square after the move\n",
    "    piece_after_move = board.piece_at(square_index)\n",
    "\n",
    "    # Check if the square is still under attack after the move\n",
    "    is_under_attack_after = is_under_attack(board, square_index) and piece_after_move is not None\n",
    "\n",
    "    # Return True if it was under attack before, but is no longer under attack\n",
    "    return was_under_attack_before and not is_under_attack_after\n",
    "\n",
    "def is_blunder(fen: str, uci_move: str, stockfish_path: str = '/opt/homebrew/bin/stockfish', threshold: int = 150) -> bool:\n",
    "    # Load the engine\n",
    "    with chess.engine.SimpleEngine.popen_uci(stockfish_path) as engine:\n",
    "        # Parse the FEN to create a board\n",
    "        board = chess.Board(fen)\n",
    "        \n",
    "        # Create the move from the UCI string\n",
    "        move = chess.Move.from_uci(uci_move)\n",
    "\n",
    "        # Check if the move is legal\n",
    "        if move not in board.legal_moves:\n",
    "            return False  # Automatically return False if the move is illegal\n",
    "\n",
    "        # Get the evaluation before the move\n",
    "        info_before = engine.analyse(board, chess.engine.Limit(time=0.1))\n",
    "        eval_before = info_before['score'].relative.score()\n",
    "\n",
    "        # If eval_before is None, it's a checkmate scenario, so return False (no blunder possible)\n",
    "        if eval_before is None:\n",
    "            return False\n",
    "\n",
    "        # Apply the move\n",
    "        board.push(move)\n",
    "\n",
    "        # Get the evaluation after the move\n",
    "        info_after = engine.analyse(board, chess.engine.Limit(time=0.1))\n",
    "        eval_after = info_after['score'].relative.score()\n",
    "\n",
    "        # If eval_after is None, it's a checkmate scenario, so return False (no blunder possible)\n",
    "        if eval_after is None:\n",
    "            return False\n",
    "\n",
    "        # Calculate the centipawn difference\n",
    "        centipawn_loss = abs(eval_before - eval_after)\n",
    "\n",
    "        # Check if the loss is greater than the threshold (150 centipawns)\n",
    "        return centipawn_loss > threshold\n",
    "\n",
    "def square_index(square_name: str) -> int:\n",
    "    if not isinstance(square_name, str) or len(square_name) != 2:\n",
    "        raise ValueError(\"Square name must be a string of length 2\")\n",
    "\n",
    "    file = square_name[0].lower()\n",
    "    rank = square_name[1]\n",
    "\n",
    "    if file not in 'abcdefgh' or rank not in '12345678':\n",
    "        raise ValueError(\"Invalid square name\")\n",
    "\n",
    "    file_index = 'abcdefgh'.index(file)\n",
    "    rank_index = '12345678'.index(rank)\n",
    "\n",
    "    return rank_index * 8 + file_index"
   ],
   "outputs": [],
   "execution_count": 81
  },
  {
   "cell_type": "code",
   "id": "1c5eb733-807b-448f-9868-769377758a76",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T19:39:44.692693Z",
     "start_time": "2024-09-30T19:35:24.152275Z"
    }
   },
   "source": [
    "squarewise_alarmbells = {\"b1\": (0, 717), \"d1\": (0, 1888), \"f1\": (0, 1864), \"h1\": (0, 1000), \"d2\": (0, 1608), \"e2\":(0, 1701), \"f2\": (0, 1747), \"a3\": (1, 416), \"c3\": (1, 1346), \"d3\": (0, 1676), \"e3\": (0, 142), \"h3\": (1, 1009), \"b4\": (1, 1), \"d4\": (0, 120), \"e4\": (1, 977), \"f4\": (1, 1846), \"g4\": (1, 538), \"h4\": (0, 437), \"b5\": (0, 1687), \"d5\": (0, 1538), \"e5\": (0, 630), \"f5\": (1, 843), \"c6\": (1, 574), \"e6\": (0, 1924), \"e7\": (0, 2029), \"f7\": (0, 1715)}\n",
    "\n",
    "squarewise_alarmbells = {\"b1\": (0, 717, 0.4865), \"d1\": (0, 1888, 0.4414), \"f1\": (0, 1864, 0.5453), \"h1\": (0, 1000, 0.29), \"d2\": (0, 1608, 0.87), \"e2\":(0, 1701, 0.1005), \"f2\": (0, 1747, 0.3497), \"a3\": (1, 416, 0.0934), \"c3\": (1, 1346, 0.2888), \"d3\": (0, 1676, 0.3614), \"e3\": (0, 142, 0.2222), \"h3\": (1, 1009, 0.2700), \"b4\": (1, 1, 1.0180), \"d4\": (0, 120, 0.4834), \"e4\": (0, 977, 0.4095), \"f4\": (0, 1846, 0.9502), \"g4\": (0, 538, 0.4124), \"h4\": (0, 437, 0.6328), \"b5\": (0, 1687, 0.2789), \"d5\": (0, 1538, 0.4424), \"e5\": (0, 630, 0.4104), \"f5\": (0, 843, 0.2159), \"c6\": (1, 574, 1.3355), \"e6\": (0, 1924, 0.5567), \"e7\": (0, 2029, 0.3414), \"f7\": (0, 1715, 0.5274)}\n",
    "\n",
    "lookup_thresholds = {0: {}, 1:{}}\n",
    "for value in squarewise_alarmbells.values():\n",
    "    lookup_thresholds[value[0]][value[1]] = value[2]\n",
    "    \n",
    "\n",
    "# squarewise_alarmbells = {\"b1\": (0, 717), \"d1\": (0, 1888), \"f1\": (0, 1864), \"h1\": (0, 1000), \"d2\": (0, 1608), \"e2\":(0, 1701), \"f2\": (0, 1747), \"a3\": (1, 416), \"c3\": (1, 1346), \"d3\": (0, 1676), \"e3\": (0, 142), \"h3\": (1, 1009)}\n",
    "\n",
    "\n",
    "target_key_list = ['transformer block 0 hidden states', 'transformer block 1 hidden states'] # 'conv_last'\n",
    "all_ground_truths = []\n",
    "intervention_site = []\n",
    "\n",
    "for_ashton = {k:[] for k in [square for square in squarewise_alarmbells]}\n",
    "\n",
    "for key, value in squarewise_alarmbells.items():\n",
    "    layer, feature_idx = value[0], value[1]\n",
    "    # layer, feature_idx = random.choice([0, 1]), random.randint(0, 2048)\n",
    "    intervention_site.append((target_key_list[layer], feature_idx))\n",
    "    ground_truth = []\n",
    "    for i in tqdm(range(len(special_fens['transitional']))):\n",
    "        fen = special_fens['transitional'][i]\n",
    "        move = best_transitional_moves[i]\n",
    "        square_idx = square_index(key)\n",
    "        try:\n",
    "            no_longer_under_attack = is_piece_no_longer_under_attack(fen, move, square_idx)\n",
    "            # micro_gt = no_longer_under_attack and is_blunder(fen, transitional_maia_moves[i][0])\n",
    "            micro_gt = no_longer_under_attack and not is_piece_no_longer_under_attack(fen, transitional_maia_moves[i][0], square_idx)\n",
    "            ground_truth.append(micro_gt)    \n",
    "            if is_piece_no_longer_under_attack(fen, move, square_idx):\n",
    "                temp = {\"fen\": fen}\n",
    "                temp[\"transition_points\"] = transition_points[i]\n",
    "                temp[\"best_moves\"] = all_best_transitional_moves[i]\n",
    "                temp['blunder'] = transitional_maia_moves[i][0]\n",
    "                for_ashton[key].append(temp)\n",
    "        except ValueError:\n",
    "            ground_truth.append(0)\n",
    "\n",
    "            # print(\"illegal_move\" + move)\n",
    "    all_ground_truths.append(ground_truth)\n",
    "    print(len(ground_truth))\n",
    "all_ground_truths = torch.tensor(all_ground_truths, dtype=torch.int)\n",
    "with open(\"non_ashtonian_relevant_positions.json\", \"w\") as f:\n",
    "    json.dump(for_ashton, f)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90562/90562 [00:10<00:00, 9026.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90562/90562 [00:10<00:00, 9045.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90562/90562 [00:10<00:00, 8927.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90562/90562 [00:10<00:00, 9036.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90562/90562 [00:09<00:00, 9091.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90562/90562 [00:09<00:00, 9092.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90562/90562 [00:10<00:00, 9015.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90562/90562 [00:10<00:00, 8994.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90562/90562 [00:09<00:00, 9074.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90562/90562 [00:10<00:00, 8979.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90562/90562 [00:09<00:00, 9127.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90562/90562 [00:09<00:00, 9160.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90562/90562 [00:10<00:00, 8540.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90562/90562 [00:09<00:00, 9110.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90562/90562 [00:09<00:00, 9146.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90562/90562 [00:09<00:00, 9268.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90562/90562 [00:10<00:00, 8953.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90562/90562 [00:09<00:00, 9102.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90562/90562 [00:09<00:00, 9107.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90562/90562 [00:10<00:00, 9045.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90562/90562 [00:10<00:00, 8955.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90562/90562 [00:10<00:00, 8994.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90562/90562 [00:09<00:00, 9103.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90562/90562 [00:09<00:00, 9073.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90562/90562 [00:09<00:00, 9066.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90562/90562 [00:09<00:00, 9141.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90562\n"
     ]
    }
   ],
   "execution_count": 82
  },
  {
   "cell_type": "code",
   "id": "5c66adf7-91b0-4659-bbb8-6de686117503",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T19:41:25.861142Z",
     "start_time": "2024-09-30T19:41:25.333211Z"
    }
   },
   "source": [
    "valid_indices = [i for i in range(all_ground_truths.shape[1]) if torch.sum(all_ground_truths[:, i]) != 0]\n",
    "\n",
    "\n",
    "filtered_special_fens = [special_fens['transitional'][i] for i in valid_indices]\n",
    "filtered_transition_points = [transition_points[i] for i in valid_indices]\n",
    "filtered_best_transitional_moves = [best_transitional_moves[i] for i in valid_indices]\n",
    "filtered_all_best_transitional_moves = [all_best_transitional_moves[i] for i in valid_indices]\n",
    "filtered_all_ground_truths = all_ground_truths[:, valid_indices]"
   ],
   "outputs": [],
   "execution_count": 83
  },
  {
   "cell_type": "code",
   "id": "e24d6b64-d1ae-4d1f-b0ef-17743630e1d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T19:41:27.194644Z",
     "start_time": "2024-09-30T19:41:26.746665Z"
    }
   },
   "source": [
    "board_fens = []\n",
    "board_inputs = []\n",
    "for fen in filtered_special_fens:\n",
    "    board_tensor = board_to_tensor(chess.Board(fen))\n",
    "    board_fens.append(fen)\n",
    "    board_inputs.append(board_tensor)\n",
    "\n",
    "board_inputs = torch.stack(board_inputs, dim=0)"
   ],
   "outputs": [],
   "execution_count": 84
  },
  {
   "cell_type": "code",
   "id": "bf6edd8a-f673-40be-b84d-c2827a5fbfe3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T19:41:28.790973Z",
     "start_time": "2024-09-30T19:41:28.785253Z"
    }
   },
   "source": [
    "torch.sum(filtered_all_ground_truths, dim=1)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 13,  21,   7,  22,  26,  63, 155,  46, 203,  74, 105,  80, 125, 556,\n",
       "        668, 153,  92,  79,  83, 209, 440,  75,  28,  40,  18,  26])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 85
  },
  {
   "cell_type": "code",
   "id": "9bb34795-96f7-4b15-8761-6c5d29958bef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T19:41:35.339240Z",
     "start_time": "2024-09-30T19:41:35.335602Z"
    }
   },
   "source": "intervention_site",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('transformer block 0 hidden states', 717),\n",
       " ('transformer block 0 hidden states', 1888),\n",
       " ('transformer block 0 hidden states', 1864),\n",
       " ('transformer block 0 hidden states', 1000),\n",
       " ('transformer block 0 hidden states', 1608),\n",
       " ('transformer block 0 hidden states', 1701),\n",
       " ('transformer block 0 hidden states', 1747),\n",
       " ('transformer block 1 hidden states', 416),\n",
       " ('transformer block 1 hidden states', 1346),\n",
       " ('transformer block 0 hidden states', 1676),\n",
       " ('transformer block 0 hidden states', 142),\n",
       " ('transformer block 1 hidden states', 1009),\n",
       " ('transformer block 1 hidden states', 1),\n",
       " ('transformer block 0 hidden states', 120),\n",
       " ('transformer block 0 hidden states', 977),\n",
       " ('transformer block 0 hidden states', 1846),\n",
       " ('transformer block 0 hidden states', 538),\n",
       " ('transformer block 0 hidden states', 437),\n",
       " ('transformer block 0 hidden states', 1687),\n",
       " ('transformer block 0 hidden states', 1538),\n",
       " ('transformer block 0 hidden states', 630),\n",
       " ('transformer block 0 hidden states', 843),\n",
       " ('transformer block 1 hidden states', 574),\n",
       " ('transformer block 0 hidden states', 1924),\n",
       " ('transformer block 0 hidden states', 2029),\n",
       " ('transformer block 0 hidden states', 1715)]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 86
  },
  {
   "cell_type": "code",
   "id": "572832e7-5e85-4a00-b7f8-78322cc266d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T19:41:37.155515Z",
     "start_time": "2024-09-30T19:41:37.129680Z"
    }
   },
   "source": [
    "sae_dim = 2048\n",
    "sae_lr = 1e-05\n",
    "sae_site = \"res\"\n",
    "sae_date = \"2023-12\"\n",
    "sae = torch.load(f'trained_saes_{sae_date}-{sae_dim}-{sae_lr}-{sae_site}.pt')\n",
    "target_key_list = ['transformer block 0 hidden states', 'transformer block 1 hidden states'] # 'conv_last'"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hp/j90w_shj791fd2xw8mx5j7xm0000gn/T/ipykernel_36566/1152157256.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  sae = torch.load(f'trained_saes_{sae_date}-{sae_dim}-{sae_lr}-{sae_site}.pt')\n"
     ]
    }
   ],
   "execution_count": 87
  },
  {
   "cell_type": "code",
   "id": "50a9adf8-6851-4000-a1f8-def059d870d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T19:41:38.848637Z",
     "start_time": "2024-09-30T19:41:38.842064Z"
    }
   },
   "source": [
    "def _enable_activation_hook(model, cfg):\n",
    "    def get_activation(name):\n",
    "        def hook(model, input, output):\n",
    "            if not hasattr(_thread_local, 'residual_streams'):\n",
    "                _thread_local.residual_streams = {}\n",
    "            _thread_local.residual_streams[name] = output.detach()\n",
    "        return hook\n",
    "        \n",
    "    for i in range(cfg.num_blocks_vit):\n",
    "        feedforward_module = model.module.transformer.elo_layers[i][1]\n",
    "        feedforward_module.register_forward_hook(get_activation(f'transformer block {i} hidden states'))\n",
    "\n",
    "def apply_sae_to_activations(sae, activations, target_key_list):\n",
    "    sae_activations = {}\n",
    "    for key in target_key_list:\n",
    "        if key in activations and key in sae:\n",
    "            # act = activations[key].view(-1, activations[key].size(-1))\n",
    "            act = torch.mean(activations[key], dim=1)\n",
    "            # print(act.shape)\n",
    "            encoded = nn.functional.linear(act, sae[key]['encoder_DF.weight'], sae[key]['encoder_DF.bias'])\n",
    "            encoded = nn.functional.relu(encoded)\n",
    "            \n",
    "            sae_activations[key] = encoded\n",
    "    \n",
    "    return sae_activations\n",
    "\n",
    "def apply_sae_to_reconstruction(sae, activations, target_key_list):\n",
    "    sae_activations = {}\n",
    "    for key in target_key_list:\n",
    "        if key in activations and key in sae:\n",
    "            act = torch.mean(activations[key], dim=1)\n",
    "            encoded = nn.functional.linear(act, sae[key]['encoder_DF.weight'], sae[key]['encoder_DF.bias'])\n",
    "            encoded = nn.functional.relu(encoded)\n",
    "            decoded = nn.functional.linear(encoded, sae[key]['decoder_FD.weight'], sae[key]['decoder_FD.bias'])\n",
    "            \n",
    "            sae_activations[key] = decoded\n",
    "    \n",
    "    return sae_activations\n",
    "\n",
    "def get_legal_moves_idx(board, all_moves_dict):\n",
    "    legal_moves = torch.zeros(len(all_moves_dict))\n",
    "    legal_moves_idx = []\n",
    "    for move in board.legal_moves:\n",
    "        move_uci = move.uci()\n",
    "        if move_uci in all_moves_dict:\n",
    "            legal_moves_idx.append(all_moves_dict[move_uci])\n",
    "    legal_moves_idx = torch.tensor(legal_moves_idx)\n",
    "    legal_moves[legal_moves_idx] = 1\n",
    "    return legal_moves"
   ],
   "outputs": [],
   "execution_count": 88
  },
  {
   "cell_type": "code",
   "id": "63c2c043-6673-4cca-bd84-5271044fe129",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T19:41:40.921276Z",
     "start_time": "2024-09-30T19:41:40.917303Z"
    }
   },
   "source": [
    "def _enable_intervention_hook(model, cfg):\n",
    "    def get_intervention_hook(name):\n",
    "        def hook(module, input, output):\n",
    "            if not hasattr(_thread_local, 'residual_streams'):\n",
    "                _thread_local.residual_streams = {}\n",
    "            _thread_local.residual_streams[name] = output.detach()\n",
    "            if hasattr(_thread_local, 'modified_values') and name in _thread_local.modified_values:\n",
    "                return _thread_local.modified_values[name]\n",
    "            return None\n",
    "        return hook\n",
    "    \n",
    "    for i in range(cfg.num_blocks_vit):\n",
    "        feedforward_module = model.module.transformer.elo_layers[i][1]\n",
    "        feedforward_module.register_forward_hook(\n",
    "            get_intervention_hook(f'transformer block {i} hidden states')\n",
    "        )\n",
    "\n",
    "def set_modified_values(modified_dict):\n",
    "    _thread_local.modified_values = modified_dict\n",
    "\n",
    "def clear_modified_values():\n",
    "    if hasattr(_thread_local, 'modified_values'):\n",
    "        del _thread_local.modified_values"
   ],
   "outputs": [],
   "execution_count": 89
  },
  {
   "cell_type": "code",
   "id": "1b37a257-75a8-4494-b211-96ba1facff9f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T19:03:10.751886Z",
     "start_time": "2024-09-30T19:03:10.749656Z"
    }
   },
   "source": [
    "change = {}"
   ],
   "outputs": [],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T04:14:38.562387Z",
     "start_time": "2024-10-01T04:14:38.548913Z"
    }
   },
   "cell_type": "code",
   "source": [
    "intervention_site = []\n",
    "for key, value in squarewise_alarmbells.items():\n",
    "    layer, feature_idx = value[0], value[1]\n",
    "    #Random intervention\n",
    "    # layer, feature_idx = random.choice([0, 1]), random.randint(0, 2048)\n",
    "    intervention_site.append((target_key_list[layer], feature_idx))\n",
    "\n",
    "\n",
    "specific_square_idx = [val[1] for val in squarewise_alarmbells.values()].index(1009)\n",
    "specific_square_name = \"h3\"\n",
    "# intervention_site[specific_square_idx] = ('transformer block 1 hidden states', 603)\n",
    "\n",
    "print(torch.sum(filtered_all_ground_truths, dim=1)[specific_square_idx])\n",
    "\n",
    "\n",
    "specific_square_idx = intervention_site[specific_square_idx][1]\n",
    "# specific_square_idx = 603"
   ],
   "id": "2e8e8afbbb6f6823",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(80)\n"
     ]
    }
   ],
   "execution_count": 112
  },
  {
   "cell_type": "code",
   "id": "abb11b8f-1922-41d9-b7b9-b8a8cf5faeb0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T04:15:54.007851Z",
     "start_time": "2024-10-01T04:14:40.226886Z"
    }
   },
   "source": [
    "_thread_local = threading.local()\n",
    "_enable_activation_hook(model, cfg)\n",
    "target_key_list = ['transformer block 0 hidden states', 'transformer block 1 hidden states']\n",
    "# all_sae_activations = {key: [] for key in target_key_list}\n",
    "# all_sae_reconstruct = {key: [] for key in target_key_list}\n",
    "intervened_pred_list = []\n",
    "\n",
    "legal_moves_list = []\n",
    "for fen in filtered_special_fens:\n",
    "    board = chess.Board(fen)\n",
    "    legal_moves_list.append(get_legal_moves_idx(board, all_moves_dict))\n",
    "legal_moves = torch.stack(legal_moves_list)\n",
    "\n",
    "elos_self = torch.zeros(len(filtered_special_fens))\n",
    "elos_oppo = torch.zeros(len(filtered_special_fens))\n",
    "intervention_strength = 10\n",
    "epsilon = 0.005\n",
    "\n",
    "for elo in range(len(elo_dict) - 1):\n",
    "    \n",
    "    elos_self = elos_self.fill_(elo).long()\n",
    "    elos_oppo = elos_oppo.fill_(elo).long()\n",
    "\n",
    "    # Clean Run\n",
    "    with torch.no_grad():\n",
    "        logits_maia, logits_side_info, logits_value = model(board_inputs, elos_self, elos_oppo)\n",
    "        activations = getattr(_thread_local, 'residual_streams', {})\n",
    "        sae_activations = apply_sae_to_activations(sae, activations, target_key_list)\n",
    "        sae_reconstruct_activations = apply_sae_to_reconstruction(sae, activations, target_key_list)\n",
    "        # for key in target_key_list:\n",
    "        #     if key in activations:\n",
    "        #         all_sae_activations[key].append(sae_activations[key])\n",
    "        #         all_sae_reconstruct[key].append(sae_reconstruct_activations[key])\n",
    "    \n",
    "        logits_maia_legal = logits_maia * legal_moves\n",
    "        preds = logits_maia_legal.argmax(dim=-1)\n",
    "\n",
    "    # Intervention\n",
    "    intervened_sae_activations = {}\n",
    "    for key in sae_activations:\n",
    "        intervened_sae_activations[key] = sae_activations[key].clone()\n",
    "    \n",
    "    threshold_statistics = {k:[0, 0] for k in [val[1] for val in squarewise_alarmbells.values()]}\n",
    "    \n",
    "    for i in range(filtered_all_ground_truths.shape[1]):\n",
    "        for j in range(filtered_all_ground_truths.shape[0]):\n",
    "            if filtered_all_ground_truths[j][i] == 1:\n",
    "                layer, feature_idx = intervention_site[j]\n",
    "                intervened_sae_activations[layer][i, feature_idx]  += epsilon\n",
    "                intervened_sae_activations[layer][i, feature_idx]  *= intervention_strength\n",
    "        \n",
    "    reconstructed_activations = {}\n",
    "    for key in intervened_sae_activations:\n",
    "        reconstructed_activations[key] = nn.functional.linear(intervened_sae_activations[key], sae[key]['decoder_FD.weight'], \n",
    "                                                              sae[key]['decoder_FD.bias']).unsqueeze(1).expand(-1, 8, -1)\n",
    "\n",
    "    # intervene_site = 'transformer block 1 hidden states'\n",
    "    _enable_intervention_hook(model, cfg)\n",
    "    set_modified_values(reconstructed_activations)\n",
    "    with torch.no_grad():\n",
    "        intervened_logits_maia, intervened_logits_side_info, intervened_logits_value = model(board_inputs, elos_self, elos_oppo)\n",
    "        intervened_logits_maia_legal = intervened_logits_maia * legal_moves\n",
    "        intervened_preds = intervened_logits_maia_legal.argmax(dim=-1)\n",
    "    clear_modified_values()\n",
    "\n",
    "    intervened_pred_list.append(intervened_preds)\n",
    "\n",
    "    # Best move rate\n",
    "\n",
    "\n",
    "    original_results_dict = {k:[0, 0] for k in [val[1] for val in intervention_site]}\n",
    "\n",
    "\n",
    "    print(f\"Maia 2 Strength: {elo}\")\n",
    "    original_cnt = 0\n",
    "    for i in range(filtered_all_ground_truths.shape[1]):\n",
    "        for j in range(filtered_all_ground_truths.shape[0]):\n",
    "            if filtered_all_ground_truths[j][i] == 1:\n",
    "         \n",
    "                pred = move_dict[preds[i].item()]\n",
    "                if pred in filtered_all_best_transitional_moves[i]:\n",
    "                    original_cnt += 1\n",
    "                    original_results_dict[intervention_site[j][1]][1] += 1\n",
    "                else:\n",
    "                    original_results_dict[intervention_site[j][1]][0] += 1\n",
    "                    pass\n",
    "                    \n",
    "    original_cnt /= filtered_all_ground_truths.shape[1]\n",
    "    print(f\"Original rate for predicting the best {specific_square_name} move: {original_results_dict[specific_square_idx][1]/(original_results_dict[specific_square_idx][0]+original_results_dict[specific_square_idx][1])}\")\n",
    "    # print(f\"Original rate for predicting the best move: {original_cnt}\")\n",
    "    # print(original_results_dict)\n",
    "\n",
    "    intervened_results_dict = {k:[0, 0] for k in [val[1] for val in intervention_site]}\n",
    "\n",
    "    intervened_cnt = 0\n",
    "    for i in range(filtered_all_ground_truths.shape[1]):\n",
    "        pred = move_dict[intervened_preds[i].item()]\n",
    "        for j in range(filtered_all_ground_truths.shape[0]):\n",
    "            if filtered_all_ground_truths[j][i] == 1:\n",
    "                if pred in filtered_all_best_transitional_moves[i]:\n",
    "                    intervened_cnt += 1\n",
    "                    intervened_results_dict[intervention_site[j][1]][1] += 1\n",
    "                else:\n",
    "                    pass\n",
    "                    intervened_results_dict[intervention_site[j][1]][0] += 1\n",
    "    intervened_cnt /= filtered_all_ground_truths.shape[1]\n",
    "    # print(f\"Intervened rate for predicting the best move: {intervened_cnt}\")\n",
    "    # print(intervened_results_dict)\n",
    "\n",
    "    print(f\"Intervened rate for predicting the best {specific_square_name} move:{intervened_results_dict[specific_square_idx][1]/(intervened_results_dict[specific_square_idx][0]+intervened_results_dict[specific_square_idx][1])}\")\n",
    "    \n",
    "intervened_pred_list = torch.stack(intervened_pred_list, dim=0)\n",
    "\n",
    "intervened_transition_points = []\n",
    "for i in range(intervened_pred_list.shape[1]):\n",
    "    intervened = False\n",
    "    for j in range(1, len(elo_dict) - 1):\n",
    "        if all(move_dict[intervened_pred_list[k][i].item()] != filtered_best_transitional_moves[i] for k in range(j)) and \\\n",
    "           all(move_dict[intervened_pred_list[k][i].item()] == filtered_best_transitional_moves[i] for k in range(j, len(elo_dict) - 1)):\n",
    "               intervened_transition_points.append(j)\n",
    "               intervened = True\n",
    "    if not intervened:\n",
    "        intervened_transition_points.append(-1)\n",
    "\n",
    "cnt = 0\n",
    "tot_sum = 0\n",
    "for i in range(intervened_pred_list.shape[1]):\n",
    "    if intervened_transition_points[i] != -1:\n",
    "        cnt += 1\n",
    "        tot_sum += (filtered_transition_points[i] - intervened_transition_points[i])\n",
    "\n",
    "print(tot_sum/cnt, cnt)\n",
    "change[intervention_strength] = tot_sum/cnt"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maia 2 Strength: 0\n",
      "Original rate for predicting the best h3 move: 0.0375\n",
      "Intervened rate for predicting the best h3 move:0.15\n",
      "Maia 2 Strength: 1\n",
      "Original rate for predicting the best h3 move: 0.225\n",
      "Intervened rate for predicting the best h3 move:0.4125\n",
      "Maia 2 Strength: 2\n",
      "Original rate for predicting the best h3 move: 0.325\n",
      "Intervened rate for predicting the best h3 move:0.4625\n",
      "Maia 2 Strength: 3\n",
      "Original rate for predicting the best h3 move: 0.4125\n",
      "Intervened rate for predicting the best h3 move:0.4875\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[113], line 61\u001B[0m\n\u001B[1;32m     59\u001B[0m set_modified_values(reconstructed_activations)\n\u001B[1;32m     60\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m---> 61\u001B[0m     intervened_logits_maia, intervened_logits_side_info, intervened_logits_value \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mboard_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43melos_self\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43melos_oppo\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     62\u001B[0m     intervened_logits_maia_legal \u001B[38;5;241m=\u001B[39m intervened_logits_maia \u001B[38;5;241m*\u001B[39m legal_moves\n\u001B[1;32m     63\u001B[0m     intervened_preds \u001B[38;5;241m=\u001B[39m intervened_logits_maia_legal\u001B[38;5;241m.\u001B[39margmax(dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1557\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1558\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1560\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1561\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1565\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:168\u001B[0m, in \u001B[0;36mDataParallel.forward\u001B[0;34m(self, *inputs, **kwargs)\u001B[0m\n\u001B[1;32m    166\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mautograd\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mrecord_function(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataParallel.forward\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m    167\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice_ids:\n\u001B[0;32m--> 168\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    170\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m chain(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodule\u001B[38;5;241m.\u001B[39mparameters(), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodule\u001B[38;5;241m.\u001B[39mbuffers()):\n\u001B[1;32m    171\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m t\u001B[38;5;241m.\u001B[39mdevice \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msrc_device_obj:\n",
      "File \u001B[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1557\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1558\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1560\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1561\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1565\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/Downloads/maia2-sae-main/main.py:454\u001B[0m, in \u001B[0;36mMAIA2Model.forward\u001B[0;34m(self, boards, elos_self, elos_oppo)\u001B[0m\n\u001B[1;32m    452\u001B[0m batch_size \u001B[38;5;241m=\u001B[39m boards\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m    453\u001B[0m boards \u001B[38;5;241m=\u001B[39m boards\u001B[38;5;241m.\u001B[39mview(batch_size, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcfg\u001B[38;5;241m.\u001B[39minput_channels, \u001B[38;5;241m8\u001B[39m, \u001B[38;5;241m8\u001B[39m)\n\u001B[0;32m--> 454\u001B[0m embs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mchess_cnn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mboards\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    455\u001B[0m embs \u001B[38;5;241m=\u001B[39m embs\u001B[38;5;241m.\u001B[39mview(batch_size, embs\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m1\u001B[39m), \u001B[38;5;241m8\u001B[39m \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m8\u001B[39m)\n\u001B[1;32m    456\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mto_patch_embedding(embs)\n",
      "File \u001B[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1557\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1558\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1560\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1561\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1565\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/Downloads/maia2-sae-main/main.py:298\u001B[0m, in \u001B[0;36mChessResNet.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    295\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[1;32m    297\u001B[0m     out \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mrelu(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbn1(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconv1(x)))\n\u001B[0;32m--> 298\u001B[0m     out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlayers\u001B[49m\u001B[43m(\u001B[49m\u001B[43mout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    299\u001B[0m     out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconv_last(out)\n\u001B[1;32m    300\u001B[0m     out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbn_last(out)\n",
      "File \u001B[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1557\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1558\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1560\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1561\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1565\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/container.py:219\u001B[0m, in \u001B[0;36mSequential.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    217\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[1;32m    218\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[0;32m--> 219\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    220\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1557\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1558\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1560\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1561\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1565\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/Downloads/maia2-sae-main/main.py:263\u001B[0m, in \u001B[0;36mBasicBlock.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    261\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[0;32m--> 263\u001B[0m     out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv1\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    264\u001B[0m     out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbn1(out)\n\u001B[1;32m    265\u001B[0m     out \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mrelu(out)\n",
      "File \u001B[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1557\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1558\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1560\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1561\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1565\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/conv.py:458\u001B[0m, in \u001B[0;36mConv2d.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    457\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 458\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_conv_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/conv.py:454\u001B[0m, in \u001B[0;36mConv2d._conv_forward\u001B[0;34m(self, input, weight, bias)\u001B[0m\n\u001B[1;32m    450\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mzeros\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m    451\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mconv2d(F\u001B[38;5;241m.\u001B[39mpad(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reversed_padding_repeated_twice, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode),\n\u001B[1;32m    452\u001B[0m                     weight, bias, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstride,\n\u001B[1;32m    453\u001B[0m                     _pair(\u001B[38;5;241m0\u001B[39m), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdilation, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgroups)\n\u001B[0;32m--> 454\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv2d\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstride\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    455\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdilation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 113
  },
  {
   "cell_type": "code",
   "id": "451a44fc-9260-443d-bd4b-541c4ea4f862",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
